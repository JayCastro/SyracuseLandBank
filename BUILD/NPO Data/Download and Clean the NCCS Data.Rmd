---
title: "Download and Clean the NCCS Data"
author: "Francisco Santamarina"
date: "April 18, 2017"
output:
  html_document:
    df_print: paged
    keep_md: true
      
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( message=F, warning=F )
```

## Download the Zip File

Set your working directory before downloading the .zip file. For example, please see the address in the code chunk below. Update the address as appropriate before running the code:
```{r}
# Set your working directory
setwd("~/Graduate School/PAI 690 Independent Study_DDM II/Group Project/NPO Variables")
```

Download the source data to your working directory:
```{r}
## Download Source Data:
## DropBox .zip location     set dl=1 to download
download.file( "https://www.dropbox.com/s/w68lvzr2dgjmame/BMF_Aug_2016.zip?dl=1", "BMF_Aug_2016.zip" )
unzip( "BMF_Aug_2016.zip" )

## To remove the file after downloading, please delete the "#" at the head of the line, below:
#file.remove( "BMF_Aug_2016.zip" )
```


You can see what has been unzipped by running the command dir(). Because the .zip file contained two folder levels before the data, we want to set our working directory to the folder level where our data is located, then read it into the R environment:
```{r}
setwd("~/Graduate School/PAI 690 Independent Study_DDM II/Group Project/NPO Variables/data/extracts")
dat <- read.csv( "N2s8d2m.csv" )
```
*The data dictionary for this .CSV file* is located at [the NCCS' website](http://nccsweb.urban.org/PubApps/showDD.php#Business%20Master%20Files).


## Filter the Values

The dataset that was just loaded contains information on nonprofits from across the United States. We will need to filter the dataset in two steps. 

**First**, we will subset the dataset such that it only contains nonprofits in the zip codes that compose Onondaga County. This list of zip codes has already been produced and is located on this same GitHub page. 
```{r}
## Load Filter Values: Zip Codes
zipc <- read.csv( "https://raw.githubusercontent.com/christine-brown/SyracuseLandBank/master/BUILD/NPO%20Data/Zip_Codes.csv",
                  header = FALSE, fileEncoding="UTF-8-BOM" )

## Assign the header name "zipcode" to the vector
names(zipc) <- "zipcode"

## Overwrite the variable with itself, to remove any lingering artifacts from reading the data in
zipc <- zipc$zipcode

## Apply Filter Values: Zip Codes
### Returns a dataset of rows that have a value for zip5 that is within the zipc vector
dat <- dat[ dat$zip5 %in% zipc, ]

## Since zipc is no longer necessary, remove it from the environment:
rm( zipc )
```

**Second**, now that we have a dataset that only contains NPOs with zip codes in Onondaga County, we will subset the dataset again to only return NPOs that are in the city of Syracuse. Because there is some flexibility in how the name has been reported, we will include any cities listed in the NPOs of Onondaga County dataset that end in "CUSE", and using this to further subset the data.
```{r}
## Create a vector containing a listing of the unique city names from the NPOs of Onondaga County dataset
cityNames <- as.character( unique( dat$CITY ) )

## Create a vector that contains a listing of each name within that vector that contains "CUSE"
syrNames <- grep( "CUSE", cityNames, value = T )


## Apply Filter Values: Variations of "Syracuse"
### Returns a dataset of rows that have a value for CITY that is within the syrNames vector
dat <- dat[ dat$CITY %in% syrNames, ]

## Remove unnecessary vectors from the environment:
rm( cityNames )
rm( syrNames )
```

**Finally**, let's take this subset and write it to a .CSV file, so that we can use it later as needed. This will be the raw data.
```{r}
write.csv( dat, "NPO_Data.csv", row.names=F )
```

## Geocode the Nonprofit Addresses

The package "ggmap" has a function, geocode, that allows you to query Google via the Maps API to return longitude and latitude coordinates for a street address. We will be using that function later on, when the addresses have been cleaned up and pasted together.

```{r}
library( ggmap )
```

Before we geocode the addresses, we need to clean up the various components (address, city, state, and zip code). Once we have removed any commas or periods, we can combine the components into a single string that can be geocoded using the ggmap library. 

**First**, we will create a vector that only contains the addresses of the homes to assist in this process. 

```{r}
## Create a vector that only contains address, city, state, and zip data for each NPO
address <- dat[ , c("ADDRESS","CITY", "STATE", "ZIP") ]

## Rename the column headers to only have the first letter, making them easier to work with
names( address ) <- c("a", "c", "s", "z" )

## Remove any commas in the street address
address$a <- gsub( ",", "", address$a )

## Remove any periods in the street address
address$a <- gsub( "\\.", "", address$a )

## Combine the strings in this order: Address, City, State, Zip. Each is separated with a comma and a space
addresses <- paste( address$a, address$c, address$s, address$z, sep=", " )


```

**Second**, we will geocode the addresses. Please note that there is a limit to how many addresses Google will geocode for free. A data scientist who hit the 2,500 address-per-day cap developed an alternative to batch geocoding, which can be found [here](http://www.shanelynn.ie/massive-geocoding-with-r-and-google-maps/). 
Once we have the addresses, we will bind the columns back into the original dataset, so that each NPO now has two additional columns of data: one a longitudinal coordinate, and the other a latitudinal coordinate.

```{r}
## Translate the address strings to latitude and longitude coordinates
lat.long <- geocode( addresses )

## Bind the geocoded addresses to the dataset
dat <- cbind( dat, lat.long )

## Remove unnecessary vectors from the environment:
rm( addresses )
```

**Finally**, let's take the NPO dataset that contains longitude-latitude coordinates and write it to a .CSV file, so that we can use it later as needed. This will be assist in processing data.

```{r}
# Generate a .CSV file that contains geocoded coordinates.

setwd( "C:/Users/franc/Documents/GitHub/DDM-II/SyracuseLandBank/NPO Data" )
write.csv( dat, "NPO_Data_geocoded.csv", row.names=F )

```

